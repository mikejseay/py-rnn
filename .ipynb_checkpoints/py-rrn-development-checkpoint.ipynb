{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from numpy.testing import assert_allclose, assert_array_equal\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "from scipy.stats import norm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "import network as N\n",
    "\n",
    "rng_seed = 1234\n",
    "rng = np.random.RandomState(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new, useful code!\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def assert_allcombs_equal(iter_arr, ck_fun=assert_allclose):\n",
    "    combs = combinations(iter_arr, 2)\n",
    "    for comb in combs:\n",
    "        ck_fun(*comb)\n",
    "\n",
    "def imshow_cb(a, ax):\n",
    "    \n",
    "    i = ax.imshow(a, cmap='RdBu_r')\n",
    "    cb = plt.colorbar(i)\n",
    "\n",
    "    lims = cb.get_clim()\n",
    "    maxabs = np.fabs(lims).max()\n",
    "    cb.set_clim(-maxabs, maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/Users/michaelseay/Code/py-rrn/network.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_params = {'n_units': 800,\n",
    "                 'p_plastic': 0.6,\n",
    "                 'p_connect': 0.1,\n",
    "                 'syn_strength': 1.5,\n",
    "                 'tau_ms': 10,\n",
    "                 'sigmoid': np.tanh,\n",
    "                 'noise_amp': 0.001}\n",
    "\n",
    "trial_params = {'length_ms': 1000,\n",
    "                'spacing': 2,\n",
    "                'time_step': 1,\n",
    "                'start_train_ms': 250,\n",
    "                'end_train_ms': 1400,}\n",
    "\n",
    "input_params = {'n_units': 1,\n",
    "                'value': 5,\n",
    "                'start_ms': 200,\n",
    "                'duration_ms': 50}\n",
    "\n",
    "output_params = {'n_units': 1,\n",
    "                 'value': 1,\n",
    "                'center_ms': 1250,\n",
    "                'width_ms': 30,\n",
    "                'baseline_val': 0.2}\n",
    "\n",
    "train_params = {'n_trials_recurrent': 20,\n",
    "                'n_trials_readout': 10,\n",
    "                'n_trials_test': 10}\n",
    "\n",
    "Net = N.Network(**network_params)\n",
    "Tryal = N.Trial(**trial_params)\n",
    "In = N.Input(Tryal, **input_params)\n",
    "Out = N.Output(Tryal, **output_params)\n",
    "Train = N.Trainer(Net, In, Out, Tryal, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## connectivity matrices\n",
    "\n",
    "# \"generator\" network recurrent weight matrix (WXX)\n",
    "# indices are define as WXX[postsyn, presyn]\n",
    "\n",
    "# logical mask for non-zero connections\n",
    "WXX_mask = np.random.rand(Net.n_units, Net.n_units)  # uniform distribution!\n",
    "WXX_mask[WXX_mask <= Net.p_connect] = 1\n",
    "WXX_mask[WXX_mask < 1] = 0\n",
    "\n",
    "# connection weights\n",
    "WXX_vals = np.random.normal(scale=Net.scale_recurr, size=(Net.n_units, Net.n_units))\n",
    "\n",
    "# create non-sparse version of WXX and set self-connections (diagonal elements) to 0\n",
    "WXX_nonsparse = WXX_vals * WXX_mask\n",
    "np.fill_diagonal(WXX_nonsparse, 0)\n",
    "\n",
    "# convert to be sparse\n",
    "WXX = csr_matrix(WXX_nonsparse)\n",
    "WXX_c = csc_matrix(WXX_nonsparse) # for testing\n",
    "WXX_o = coo_matrix(WXX_nonsparse) # for testing\n",
    "\n",
    "# make a copy\n",
    "WXX_ini = WXX.copy()\n",
    "\n",
    "# input => generator weights\n",
    "WInputX = np.random.normal(scale=1, size=(Net.n_units, In.n_units))\n",
    "\n",
    "# generator weights => output\n",
    "WXOut = np.random.normal(scale=1/np.sqrt(Net.n_units), size=(Out.n_units, Net.n_units))\n",
    "\n",
    "# make a copy\n",
    "WXOut_ini = WXOut.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (800, 800) -0.647480618689 0.677844715749\n",
      "<class 'scipy.sparse.csr.csr_matrix'> (800, 800) -0.647480618689 0.677844715749\n",
      "<class 'scipy.sparse.csc.csc_matrix'> (800, 800) -0.647480618689 0.677844715749\n",
      "<class 'scipy.sparse.coo.coo_matrix'> (800, 800) -0.647480618689 0.677844715749\n",
      "<class 'numpy.ndarray'> (800, 1) -3.58742954076 2.9278030976\n",
      "<class 'numpy.ndarray'> (1, 800) -0.132783321659 0.105244799403\n"
     ]
    }
   ],
   "source": [
    "# check type size and range of these mats\n",
    "\n",
    "ck_mats = (WXX_nonsparse, WXX, WXX_c, WXX_o, WInputX, WXOut)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(type(cm), cm.shape, np.min(cm), np.max(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trial training time indices\n",
    "\n",
    "start_train_n = np.round(Tryal.start_train_ms/Tryal.time_step)\n",
    "end_train_n = np.round(Tryal.end_train_ms/Tryal.time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main loop\n",
    "\n",
    "# vectors representing the activity of the RRN units and ouputs over time\n",
    "X_history = np.zeros((Net.n_units, Tryal.n_steps))\n",
    "Out_history = np.zeros((Out.n_units, Tryal.n_steps))\n",
    "\n",
    "# ???\n",
    "WXOut_len = np.zeros((1, Tryal.n_steps))\n",
    "WXX_len = np.zeros((1, Tryal.n_steps))\n",
    "dW_readout_len = np.zeros((1, Tryal.n_steps))\n",
    "dW_recurr_len = np.zeros((1, Tryal.n_steps))\n",
    "train_window = 0\n",
    "\n",
    "# initial conditions\n",
    "\n",
    "# initial Xv is random uniform distribution from -1 to +1\n",
    "# this represents an analog firing rate\n",
    "Xv = 2 * np.random.rand(Net.n_units, 1) - 1\n",
    "\n",
    "# X is the sigmoid (tanh) of Xv, which will be bound from -0.76 to +0.76\n",
    "# which represents a membrane potential\n",
    "# as firing rate increases,\n",
    "# membrane potential increases less quickly than linearly\n",
    "X = Net.sigmoid(Xv)\n",
    "\n",
    "O = np.zeros((Out.n_units,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelseay/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py:531: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "# what does the sigmoid do?\n",
    "\n",
    "s = np.linspace(-1, 1, 100)\n",
    "h = Net.sigmoid(s)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.plot(s, h)\n",
    "# ax.plot(s, s, 'k--')\n",
    "ax.set_xlabel('Firing Rate')\n",
    "ax.set_ylabel('Membrane Potential (uV)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (800, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (800, 1) -0.999716542914 0.998805284375\n",
      "<class 'numpy.ndarray'> (800, 1) -0.761475085551 0.761091949335\n",
      "<class 'numpy.ndarray'> (1, 1) 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# check type size and range of these mats\n",
    "\n",
    "ck_mats = (X_history, Out_history, WXOut_len, WXX_len,\n",
    "           dW_readout_len, dW_recurr_len, Xv, X, O)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(type(cm), cm.shape, np.min(cm), np.max(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integration loop\n",
    "\n",
    "# constant value by which the update to Xv based on the summation\n",
    "# of recurrent generator network inputs AND external input inputs\n",
    "# AND noise, are divided...\n",
    "# this simulates a neural time constant?\n",
    "time_div = Net.tau_ms / Tryal.time_step\n",
    "\n",
    "for i in range(Tryal.n_steps):\n",
    "\n",
    "    # update units\n",
    "    \n",
    "    # (In.n_units, 1)\n",
    "    in_vec = input_pattern[:, i]\n",
    "    \n",
    "    # (Net.n_units, 1)\n",
    "    noise = use_noiseamp * np.random.normal(scale=np.sqrt(Tryal.time_step), size=(Net.n_units,1))\n",
    "    \n",
    "    \n",
    "#     Xv_current = \\\n",
    "#         WXX * X \\ # (Net.n_units, Net.n_units) * (Net.n_units, 1) => (Net.n_units, 1)\n",
    "#         + \\\n",
    "#         WInputX * in_vec \\ # (Net.n_units, In.n_units) * (In.n_units, 1) => (Net.n_units, 1)\n",
    "#         + \\\n",
    "#         noise # (Net.n_units, 1)\n",
    "    Xv_current = WXX * X + WInputX * in_vec + noise\n",
    "    \n",
    "    Xv += \\\n",
    "        (-Xv + Xv_current) \\\n",
    "        / \\\n",
    "        time_div\n",
    "    Xv += (-Xv + Xv_current) / time_div\n",
    "    X = Net.sigmoid(Xv)\n",
    "    Out = WXOut * X\n",
    "\n",
    "    # start-end training window\n",
    "    if (i == start_train_n)\n",
    "        train_window = 1\n",
    "    end\n",
    "    if (i == end_train_n)\n",
    "        train_window = 0\n",
    "    end\n",
    "\n",
    "    # training\n",
    "    if (train_window == 1 && rem(i,learn_every) == 0)\n",
    "\n",
    "        if TRAIN_RECURR == 1\n",
    "            # train recurrent\n",
    "            error = X - Target_innate_X(:,i)\n",
    "            for plas = 1:numplastic_Units\n",
    "                X_pre_plastic = X(pre_plastic_units(plas).inds)\n",
    "                P_recurr_old = P_recurr(plas).P\n",
    "                P_recurr_old_X = P_recurr_old*X_pre_plastic\n",
    "                den_recurr = 1 + X_pre_plastic'*P_recurr_old_X\n",
    "                P_recurr(plas).P = P_recurr_old - (P_recurr_old_X*P_recurr_old_X')/den_recurr\n",
    "                # update network matrix\n",
    "                dW_recurr = -error(plas)*(P_recurr_old_X/den_recurr)'\n",
    "                WXX(plas,pre_plastic_units(plas).inds) = WXX(plas,pre_plastic_units(plas).inds) + dW_recurr\n",
    "                # store change in weights\n",
    "                dW_recurr_len(i) = dW_recurr_len(i) + np.sqrt(dW_recurr*dW_recurr')\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if TRAIN_READOUT == 1\n",
    "            # update inverse correlation matrix (using property P' = P)\n",
    "            P_readout_old = P_readout\n",
    "            P_readout_old_X = P_readout_old*X\n",
    "            den_readout = 1 + X'*P_readout_old_X\n",
    "            P_readout = P_readout_old - (P_readout_old_X*P_readout_old_X')/den_readout\n",
    "            # update error\n",
    "            error = Out - target_Out(i)\n",
    "            # update output weights\n",
    "            dW_readout = -error*(P_readout_old_X/den_readout)'\n",
    "            WXOut = WXOut + dW_readout\n",
    "            # store change in weights\n",
    "            dW_readout_len(i) = np.sqrt(dW_readout*dW_readout')\n",
    "        end\n",
    "\n",
    "    end\n",
    "    # store output\n",
    "    Out_history(:,i) = Out\n",
    "    X_history(:,i) = X\n",
    "    WXOut_len(i) = np.sqrt(sum(reshape(WXOut.^2,numOut*numUnits,1)))\n",
    "    WXX_len(i) = np.sqrt(sum(reshape(WXX.^2,numUnits^2,1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw matlab code\n",
    "\n",
    "WXOut_len = np.zeros((1, Tryal.n_steps))\n",
    "WXX_len = np.zeros((1, Tryal.n_steps))\n",
    "dW_readout_len = np.zeros((1, Tryal.n_steps))\n",
    "dW_recurr_len = np.zeros((1, Tryal.n_steps))\n",
    "train_window = 0\n",
    "\n",
    "# initial conditions\n",
    "Xv = 1*(2*np.random.rand(numUnits,1)-1)\n",
    "X = Net.sigmoid(Xv)\n",
    "Out = np.zeros(numOut,1)\n",
    "\n",
    "\n",
    "# integration loop\n",
    "for i = 1:n_steps\n",
    "\n",
    "    if rem(i,round(n_steps/10)) == 0 && (TRAIN_RECURR == 1 || TRAIN_READOUT == 1)\n",
    "        fprintf('.')\n",
    "    end\n",
    "\n",
    "    in_vec= input_pattern(:,i)\n",
    "\n",
    "    # update units\n",
    "    noise = use_noiseamp*np.random.normal(numUnits,1)*np.sqrt(Tryal.time_step)\n",
    "    Xv_current = WXX*X + WInputX*in_vec+ noise\n",
    "    Xv = Xv + ((-Xv + Xv_current)./tau)*Tryal.time_step\n",
    "    X = Net.sigmoid(Xv)\n",
    "    Out = WXOut*X\n",
    "\n",
    "    # start-end training window\n",
    "    if (i == start_train_n)\n",
    "        train_window = 1\n",
    "    end\n",
    "    if (i == end_train_n)\n",
    "        train_window = 0\n",
    "    end\n",
    "\n",
    "    # training\n",
    "    if (train_window == 1 && rem(i,learn_every) == 0)\n",
    "\n",
    "        if TRAIN_RECURR == 1\n",
    "            # train recurrent\n",
    "            error = X - Target_innate_X(:,i)\n",
    "            for plas = 1:numplastic_Units\n",
    "                X_pre_plastic = X(pre_plastic_units(plas).inds)\n",
    "                P_recurr_old = P_recurr(plas).P\n",
    "                P_recurr_old_X = P_recurr_old*X_pre_plastic\n",
    "                den_recurr = 1 + X_pre_plastic'*P_recurr_old_X\n",
    "                P_recurr(plas).P = P_recurr_old - (P_recurr_old_X*P_recurr_old_X')/den_recurr\n",
    "                # update network matrix\n",
    "                dW_recurr = -error(plas)*(P_recurr_old_X/den_recurr)'\n",
    "                WXX(plas,pre_plastic_units(plas).inds) = WXX(plas,pre_plastic_units(plas).inds) + dW_recurr\n",
    "                # store change in weights\n",
    "                dW_recurr_len(i) = dW_recurr_len(i) + np.sqrt(dW_recurr*dW_recurr')\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if TRAIN_READOUT == 1\n",
    "            # update inverse correlation matrix (using property P' = P)\n",
    "            P_readout_old = P_readout\n",
    "            P_readout_old_X = P_readout_old*X\n",
    "            den_readout = 1 + X'*P_readout_old_X\n",
    "            P_readout = P_readout_old - (P_readout_old_X*P_readout_old_X')/den_readout\n",
    "            # update error\n",
    "            error = Out - target_Out(i)\n",
    "            # update output weights\n",
    "            dW_readout = -error*(P_readout_old_X/den_readout)'\n",
    "            WXOut = WXOut + dW_readout\n",
    "            # store change in weights\n",
    "            dW_readout_len(i) = np.sqrt(dW_readout*dW_readout')\n",
    "        end\n",
    "\n",
    "    end\n",
    "    # store output\n",
    "    Out_history(:,i) = Out\n",
    "    X_history(:,i) = X\n",
    "    WXOut_len(i) = np.sqrt(sum(reshape(WXOut.^2,numOut*numUnits,1)))\n",
    "    WXX_len(i) = np.sqrt(sum(reshape(WXX.^2,numUnits^2,1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n",
      "(1, 1600)\n",
      "(1, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x114726550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check: plot input and output patterns\n",
    "\n",
    "print(Tryal.time_ms.shape)\n",
    "print(In.series.shape)\n",
    "print(Out.series.shape)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(Tryal.time_ms, In.series.T, label='input')\n",
    "ax.plot(Tryal.time_ms, Out.series.T, label='output')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick verification that all of the following ways of creating\n",
    "# a matrix containing random normal numbers\n",
    "# are equivalent\n",
    "\n",
    "prng = RandomState(1234) # note one needs to re-call this to get same results every time\n",
    "test1 = prng.normal(size=(Net.n_units, Net.n_units)) * Net.scale_recurr\n",
    "\n",
    "prng = RandomState(1234)\n",
    "test2 = prng.normal(scale=Net.scale_recurr, size=(Net.n_units, Net.n_units))\n",
    "\n",
    "prng = RandomState(1234)\n",
    "test3 = norm.rvs(scale=Net.scale_recurr, size=(Net.n_units, Net.n_units), random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_allcombs_equal((test1, test2, test3), ck_fun=assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing equality / speed of generating random sparse matrices\n",
    "\n",
    "# method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# uniform distribution for mask\n",
    "prng = RandomState(1234)\n",
    "WXX_mask = prng.rand(Net.n_units, Net.n_units)\n",
    "WXX_mask[WXX_mask <= Net.p_connect] = 1\n",
    "WXX_mask[WXX_mask < 1] = 0\n",
    "\n",
    "# normal distribution for vals\n",
    "prng = RandomState(1234)\n",
    "WXX_vals = prng.normal(scale=Net.scale_recurr, size=(Net.n_units, Net.n_units))\n",
    "\n",
    "# create non-sparse version of WXX and set self-connections (diagonal elements) to 0\n",
    "WXX_nonsparse = WXX_vals * WXX_mask\n",
    "np.fill_diagonal(WXX_nonsparse, 0)\n",
    "# WXX_nonsparse[np.diag_indices_from(WXX_nonsparse)] = 0\n",
    "\n",
    "# convert to be sparse\n",
    "# WXX = coo_matrix(WXX_nonsparse)\n",
    "WXX = csr_matrix(WXX_nonsparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rvs = norm(scale=Net.scale_recurr).rvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelseay/anaconda/lib/python3.5/site-packages/scipy/sparse/compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "# random variable generator object\n",
    "prng = RandomState(1234)\n",
    "WXX_s = random(Net.n_units, Net.n_units, density=Net.p_connect, random_state=prng, data_rvs=rvs,\n",
    "               format='csr',)\n",
    "#                format='csr',)\n",
    "# WXX_s[np.diag_indices_from(WXX_s)] = 0\n",
    "WXX_s.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800) 63797 -0.775266142687 0.726642624784\n"
     ]
    }
   ],
   "source": [
    "cm = WXX_nonsparse\n",
    "print(cm.shape, np.count_nonzero(cm), cm.min(), cm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800) 63797 63797 -0.775266142687 0.726642624784\n",
      "(800, 800) 64723 63923 -0.742525396081 0.73124373277\n"
     ]
    }
   ],
   "source": [
    "ck_mats = (WXX, WXX_s)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(cm.shape, cm.nnz, cm.count_nonzero(), cm.min(), cm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "imshow_cb(WXX.toarray(), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "imshow_cb(WXX_s.toarray(), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second method is slower :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_mats = (WXX_nonsparse, WXX, WXX_c, WXX_o, WInputX, WXOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 700 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_ns = WXX_nonsparse*X # SLOW, WRONG SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.41 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 60.6 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1 = WXX*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 62.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_c = WXX_c*X # NO DIFFERENCE WITH ROW / COLUMN SPARSE MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 159 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_o = WXX_o*X # COO sparse matrix is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800)\n",
      "(800, 1)\n",
      "(800, 1)\n",
      "(800, 1)\n"
     ]
    }
   ],
   "source": [
    "test1_ns = WXX_nonsparse*X # SLOW, WRONG SHAPE\n",
    "test1 = WXX*X\n",
    "test1_c = WXX_c*X # NO DIFFERENCE WITH ROW / COLUMN SPARSE MATRICES\n",
    "test1_o = WXX_o*X # COO sparse matrix is slower\n",
    "\n",
    "print(test1_ns.shape)\n",
    "print(test1.shape)\n",
    "print(test1_c.shape)\n",
    "print(test1_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_mats = (test1, test1_c, test1_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats, assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.99 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 69.7 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_ns = WXX_nonsparse.dot(X) # ONLY VERY SLIGHTLY SLOWER THAN\n",
    "# SPARSE, CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 63.1 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2 = WXX.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 62.4 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_c = WXX_c.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 160 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_o = WXX_o.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2_ns = WXX_nonsparse.dot(X) # ONLY VERY SLIGHTLY SLOWER THAN\n",
    "# SPARSE, CORRECT BUT NUMERICALLY SLIGHTLY DIFFERENT?\n",
    "test2 = WXX.dot(X)\n",
    "test2_c = WXX_c.dot(X)\n",
    "test2_o = WXX_o.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck_mats = (test1, test1_c, test1_o, test2, test2_c, test2_o, test2_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ck_mats = (test2, test2_c, test2_o,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats, ck_fun=assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 69.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test3_ns = np.matmul(WXX_nonsparse, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object arrays are not currently supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-8f9de1d16825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test3 = np.matmul(WXX, X)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-58>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object arrays are not currently supported"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test3 = np.matmul(WXX, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion, for multiplying the sparse matrix by a vector, it's fastest\n",
    "# for a csr_matrix and just use the * operator, it will do the matrix\n",
    "# multiplication in about 60 us"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
