{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from numpy.testing import assert_allclose, assert_array_equal\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "from scipy.stats import norm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "import network as N\n",
    "\n",
    "rng_seed = 1234\n",
    "rng = np.random.RandomState(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new, useful code!\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def assert_allcombs_equal(iter_arr, ck_fun=assert_allclose):\n",
    "    combs = combinations(iter_arr, 2)\n",
    "    for comb in combs:\n",
    "        ck_fun(*comb)\n",
    "\n",
    "def imshow_cb(a, ax):\n",
    "    \n",
    "    i = ax.imshow(a, cmap='RdBu_r')\n",
    "    cb = plt.colorbar(i)\n",
    "\n",
    "    lims = cb.get_clim()\n",
    "    maxabs = np.fabs(lims).max()\n",
    "    cb.set_clim(-maxabs, maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from 'C:\\\\Users\\\\mikejseay\\\\.babun\\\\cygwin\\\\home\\\\mikejseay\\\\python\\\\py-rrn\\\\network.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NETWORK_PARAMS = {'n_units': 800,\n",
    "                 'p_plastic': 0.6,\n",
    "                 'p_connect': 0.1,\n",
    "                 'syn_strength': 1.5,\n",
    "                 'tau_ms': 10,\n",
    "                 'sigmoid': np.tanh,\n",
    "                 'noise_amp': 0.001}\n",
    "\n",
    "TRIAL_PARAMS = {'length_ms': 1000,\n",
    "                'spacing': 2,\n",
    "                'time_step': 1,\n",
    "                'start_train_ms': 250,\n",
    "                'end_train_ms': 1400,}\n",
    "\n",
    "INPUT_PARAMS = {'n_units': 1,\n",
    "                'value': 5,\n",
    "                'start_ms': 200,\n",
    "                'duration_ms': 50}\n",
    "\n",
    "OUTPUT_PARAMS = {'n_units': 1,\n",
    "                 'value': 1,\n",
    "                'center_ms': 1250,\n",
    "                'width_ms': 30,\n",
    "                'baseline_val': 0.2}\n",
    "\n",
    "TRAIN_PARAMS = {'n_trials_recurrent': 20,\n",
    "                'n_trials_readout': 10,\n",
    "                'n_trials_test': 10}\n",
    "\n",
    "NET = N.Network(**NETWORK_PARAMS)\n",
    "TRYAL = N.Trial(**TRIAL_PARAMS)\n",
    "IN = N.Input(TRYAL, **INPUT_PARAMS)\n",
    "OUT = N.Output(TRYAL, **OUTPUT_PARAMS)\n",
    "TRAIN = N.Trainer(NET, In, Out, TRYAL, **TRAIN_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## connectivity matrices\n",
    "\n",
    "# \"generator\" network recurrent weight matrix (WXX)\n",
    "# indices are define as WXX[postsyn, presyn]\n",
    "\n",
    "# logical mask for non-zero connections\n",
    "WXX_mask = np.random.rand(NET.n_units, NET.n_units)  # uniform distribution!\n",
    "WXX_mask[WXX_mask <= NET.p_connect] = 1\n",
    "WXX_mask[WXX_mask < 1] = 0\n",
    "\n",
    "# connection weights\n",
    "WXX_vals = np.random.normal(scale=NET.scale_recurr, size=(NET.n_units, NET.n_units))\n",
    "\n",
    "# create non-sparse version of WXX and set self-connections (diagonal elements) to 0\n",
    "WXX_nonsparse = WXX_vals * WXX_mask\n",
    "np.fill_diagonal(WXX_nonsparse, 0)\n",
    "\n",
    "# convert to be sparse\n",
    "WXX = csr_matrix(WXX_nonsparse)\n",
    "WXX_c = csc_matrix(WXX_nonsparse) # for testing\n",
    "WXX_o = coo_matrix(WXX_nonsparse) # for testing\n",
    "\n",
    "# make a copy\n",
    "WXX_ini = WXX.copy()\n",
    "\n",
    "# input => generator weights\n",
    "WInputX = np.random.normal(scale=1, size=(NET.n_units, IN.n_units))\n",
    "\n",
    "# generator weights => output\n",
    "WXOut = np.random.normal(scale=1/np.sqrt(NET.n_units), size=(OUT.n_units, NET.n_units))\n",
    "\n",
    "# make a copy\n",
    "WXOut_ini = WXOut.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (800, 800) -0.712367885839 0.682179562536\n",
      "<class 'numpy.ndarray'> (800, 1) -2.85951737814 3.39999673802\n",
      "<class 'numpy.ndarray'> (1, 800) -0.129000894302 0.103346968703\n"
     ]
    }
   ],
   "source": [
    "# check type size and range of these mats\n",
    "\n",
    "# ck_mats = (WXX_nonsparse, WXX, WXX_c, WXX_o, WInputX, WXOut)\n",
    "ck_mats = (WXX, WInputX, WXOut)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(type(cm), cm.shape, np.min(cm), np.max(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "# trial training time indices\n",
    "\n",
    "print(TRYAL.start_train_n)\n",
    "print(TRYAL.end_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracking histories\n",
    "\n",
    "# vectors representing the activity of the RRN units and ouputs over time\n",
    "X_history = np.zeros((NET.n_units, TRYAL.n_steps))\n",
    "Out_history = np.zeros((OUT.n_units, TRYAL.n_steps))\n",
    "\n",
    "# logging changes and such\n",
    "WXOut_len = np.zeros((TRYAL.n_steps))\n",
    "WXX_len = np.zeros((TRYAL.n_steps))\n",
    "dW_readout_len = np.zeros((TRYAL.n_steps))\n",
    "dW_recurr_len = np.zeros((TRYAL.n_steps))\n",
    "train_window = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (800, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1, 1600) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1600,) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1600,) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1600,) 0.0 0.0\n",
      "<class 'numpy.ndarray'> (1600,) 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# check type size and range of these mats\n",
    "\n",
    "ck_mats = (X_history, Out_history, WXOut_len, WXX_len, dW_readout_len, dW_recurr_len)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(type(cm), cm.shape, np.min(cm), np.max(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "\n",
    "# initial Xv is random uniform distribution from -1 to +1\n",
    "# this represents an analog firing rate\n",
    "Xv = 2 * np.random.rand(NET.n_units, 1) - 1\n",
    "\n",
    "# X is the sigmoid (tanh) of Xv, which will be bound from -0.76 to +0.76\n",
    "# which represents a membrane potential\n",
    "# as firing rate increases,\n",
    "# membrane potential increases less quickly than linearly\n",
    "X = NET.sigmoid(Xv)\n",
    "\n",
    "# O represents the output, where each output is the output-weighted membrane potential of each neuron\n",
    "# O is random normal from -0.1 to 0.1\n",
    "O = np.zeros((OUT.n_units,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (800, 1) -0.998269170598 0.999423342346\n",
      "<class 'numpy.ndarray'> (800, 1) -0.760866293283 0.761351868156\n",
      "<class 'numpy.ndarray'> (1, 1) 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# check type size and range of these mats\n",
    "\n",
    "ck_mats = (Xv, X, O)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(type(cm), cm.shape, np.min(cm), np.max(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikejseay\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "# what does the sigmoid do?\n",
    "\n",
    "s = np.linspace(-1, 1, 100)\n",
    "h = NET.sigmoid(s)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.plot(s, h)\n",
    "# ax.plot(s, s, 'k--')\n",
    "ax.set_xlabel('Firing Rate')\n",
    "ax.set_ylabel('Membrane Potential (uV)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_RECURR = False\n",
    "TRAIN_READOUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 439/1600 [00:09<00:23, 49.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-22c22d7e571e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mX_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mWXOut_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWXOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mWXX_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWXX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\mikejseay\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mikejseay\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    548\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m            \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m            indptr, indices, data)\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# integration loop\n",
    "\n",
    "# constant value by which the update to Xv based on the summation\n",
    "# of recurrent generator network inputs AND external input inputs\n",
    "# AND noise, are divided...\n",
    "# this simulates a neural time constant?\n",
    "use_noiseamp = 0\n",
    "time_div = NET.tau_ms / TRYAL.time_step\n",
    "\n",
    "for i in tqdm(range(TRYAL.n_steps)):\n",
    "\n",
    "    # update units\n",
    "    \n",
    "    # (IN.n_units, 1)\n",
    "    in_vec = IN.series[:, i]\n",
    "    \n",
    "    # (NET.n_units, 1)\n",
    "    noise = use_noiseamp * np.random.normal(scale=np.sqrt(TRYAL.time_step), size=(NET.n_units,1))\n",
    "    \n",
    "    \n",
    "#     Xv_current = \\\n",
    "#         WXX * X \\ # (NET.n_units, NET.n_units) * (NET.n_units, 1) => (NET.n_units, 1)\n",
    "#         + \\\n",
    "#         WInputX * in_vec \\ # (NET.n_units, IN.n_units) * (IN.n_units, 1) => (NET.n_units, 1)\n",
    "#         + \\\n",
    "#         noise # (NET.n_units, 1)\n",
    "\n",
    "    # note that X is the \"previous\" membrane potential (random sigmoid vector scaled to .76)\n",
    "    # WXX * X is the weighted previous membrane potential (sparse random normal square matrix scaled to ~0.65 times X)\n",
    "    # WInputX * in_vec is the weighted input (random normal vector scaled to 4 times current input vector/scalar)\n",
    "    Xv_current = WXX * X + WInputX * in_vec + noise\n",
    "    \n",
    "#     Xv += \\  # (NET.n_units, 1)\n",
    "#         (-Xv + Xv_current) \\ (NET.n_units, 1) + (NET.n_units, 1) => (NET.n_units, 1)\n",
    "#         / \\\n",
    "#         time_div (scalar)\n",
    "    # Xv is previous firing rate\n",
    "    # we take the negative difference between that firing rate and the summed incoming membrane potentials,\n",
    "    # and divide by the time constant of the network (in this case, 10 steps)\n",
    "    # then add that the current firing rate\n",
    "    # the idea being that the change to the current firing rate in each step\n",
    "    # is the summed input of weighted membrane potentials from presynaptic units\n",
    "    Xv += (-Xv + Xv_current) / time_div\n",
    "    \n",
    "    # then we convert that newly updated firing rate back into a sigmoid\n",
    "    # to determine the new membrane potential of all neurons\n",
    "    X = NET.sigmoid(Xv) # (NET.n_units, 1) => (NET.n_units, 1)\n",
    "    \n",
    "    # then we determine all of those neurons outputs as the dot-product of their\n",
    "    # membrane potentials and output weights\n",
    "    O = np.dot(WXOut, X) # (Out.n_units, NET.n_units) *dot* (NET.n_units, 1) => (Out.n_units, 1)\n",
    "\n",
    "    # start-end training window\n",
    "    if (i == TRYAL.start_train_n):\n",
    "        train_window = True\n",
    "    if (i == TRYAL.end_train_n):\n",
    "        train_window = False\n",
    "\n",
    "    # training\n",
    "    if train_window and i % TRYAL.spacing == 0:\n",
    "\n",
    "        if TRAIN_RECURR:\n",
    "            # train recurrent\n",
    "            error = X - Target_innate_X[:, i]\n",
    "            for plas in 1:NET.n_plastic\n",
    "#                 X_pre_plastic = X(pre_plastic_units(plas).inds)\n",
    "#                 P_recurr_old = P_recurr(plas).P\n",
    "#                 P_recurr_old_X = P_recurr_old*X_pre_plastic\n",
    "#                 den_recurr = 1 + X_pre_plastic'*P_recurr_old_X\n",
    "#                 P_recurr(plas).P = P_recurr_old - (P_recurr_old_X*P_recurr_old_X')/den_recurr\n",
    "#                 # update network matrix\n",
    "#                 dW_recurr = -error(plas)*(P_recurr_old_X/den_recurr)'\n",
    "#                 WXX(plas,pre_plastic_units(plas).inds) = WXX(plas,pre_plastic_units(plas).inds) + dW_recurr\n",
    "#                 # store change in weights\n",
    "#                 dW_recurr_len(i) = dW_recurr_len(i) + np.sqrt(dW_recurr*dW_recurr')\n",
    "\n",
    "        if TRAIN_READOUT:\n",
    "            pass\n",
    "            # update inverse correlation matrix (using property P' = P)\n",
    "#             P_readout_old = P_readout\n",
    "#             P_readout_old_X = P_readout_old*X\n",
    "#             den_readout = 1 + X'*P_readout_old_X\n",
    "#             P_readout = P_readout_old - (P_readout_old_X*P_readout_old_X')/den_readout\n",
    "#             # update error\n",
    "#             error = Out - target_Out(i)\n",
    "#             # update output weights\n",
    "#             dW_readout = -error*(P_readout_old_X/den_readout)'\n",
    "#             WXOut = WXOut + dW_readout\n",
    "#             # store change in weights\n",
    "#             dW_readout_len(i) = np.sqrt(dW_readout*dW_readout')\n",
    "\n",
    "    # store output\n",
    "    Out_history[:, i] = O\n",
    "    X_history[:, [i]] = X\n",
    "    WXOut_len[i] = np.sqrt(np.sum(np.square(WXOut[:])))\n",
    "    WXX_len[i] = np.sqrt(np.sum(np.square(WXX[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NETWORK_PARAMS = {'n_units': 800,\n",
    "                 'p_plastic': 0.6,\n",
    "                 'p_connect': 0.1,\n",
    "                 'syn_strength': 1.5,\n",
    "                 'tau_ms': 10,\n",
    "                 'sigmoid': np.tanh,\n",
    "                 'noise_amp': 0.001}\n",
    "\n",
    "TRIAL_PARAMS = {'length_ms': 1000,\n",
    "                'spacing': 2,\n",
    "                'time_step': 1,\n",
    "                'start_train_ms': 250,\n",
    "                'end_train_ms': 1400,}\n",
    "\n",
    "INPUT_PARAMS = {'n_units': 1,\n",
    "                'value': 5,\n",
    "                'start_ms': 200,\n",
    "                'duration_ms': 50}\n",
    "\n",
    "OUTPUT_PARAMS = {'n_units': 1,\n",
    "                 'value': 1,\n",
    "                'center_ms': 1250,\n",
    "                'width_ms': 30,\n",
    "                'baseline_val': 0.2}\n",
    "\n",
    "TRAIN_PARAMS = {'n_trials_recurrent': 20,\n",
    "                'n_trials_readout': 10,\n",
    "                'n_trials_test': 10}\n",
    "\n",
    "NET = N.Network(**NETWORK_PARAMS)\n",
    "TRYAL = N.Trial(**TRIAL_PARAMS)\n",
    "IN = N.Input(TRYAL, **INPUT_PARAMS)\n",
    "OUT = N.Output(TRYAL, **OUTPUT_PARAMS)\n",
    "TRAIN = N.Trainer(NET, In, Out, TRYAL, **TRAIN_PARAMS)\n",
    "\n",
    "WXX_mask = np.random.rand(NET.n_units, NET.n_units)  # uniform distribution!\n",
    "WXX_mask[WXX_mask <= NET.p_connect] = 1\n",
    "WXX_mask[WXX_mask < 1] = 0\n",
    "WXX_vals = np.random.normal(scale=NET.scale_recurr, size=(NET.n_units, NET.n_units))\n",
    "WXX_nonsparse = WXX_vals * WXX_mask\n",
    "np.fill_diagonal(WXX_nonsparse, 0)\n",
    "\n",
    "WXX = csr_matrix(WXX_nonsparse)\n",
    "WInputX = np.random.normal(scale=1, size=(NET.n_units, IN.n_units))\n",
    "WXOut = np.random.normal(scale=1/np.sqrt(NET.n_units), size=(OUT.n_units, NET.n_units))\n",
    "\n",
    "\n",
    "WXX_ini = WXX.copy()\n",
    "WXOut_ini = WXOut.copy()\n",
    "\n",
    "X_history = np.zeros((NET.n_units, TRYAL.n_steps))\n",
    "Out_history = np.zeros((OUT.n_units, TRYAL.n_steps))\n",
    "WXOut_len = np.zeros((TRYAL.n_steps))\n",
    "WXX_len = np.zeros((TRYAL.n_steps))\n",
    "dW_readout_len = np.zeros((TRYAL.n_steps))\n",
    "dW_recurr_len = np.zeros((TRYAL.n_steps))\n",
    "\n",
    "Xv = 2 * np.random.rand(NET.n_units, 1) - 1\n",
    "X = NET.sigmoid(Xv)\n",
    "O = np.zeros((OUT.n_units,1))\n",
    "\n",
    "TRAIN_RECURR = False\n",
    "TRAIN_READOUT = False\n",
    "train_window = 0\n",
    "\n",
    "use_noiseamp = 0\n",
    "time_div = NET.tau_ms / TRYAL.time_step\n",
    "\n",
    "for i in tqdm(range(TRYAL.n_steps)):\n",
    "\n",
    "    in_vec = IN.series[:, i]\n",
    "    noise = use_noiseamp * np.random.normal(scale=np.sqrt(TRYAL.time_step), size=(NET.n_units,1))\n",
    "    Xv_current = WXX * X + WInputX * in_vec + noise\n",
    "    Xv += (-Xv + Xv_current) / time_div\n",
    "    X = NET.sigmoid(Xv)\n",
    "    O = np.dot(WXOut, X)\n",
    "\n",
    "    if (i == TRYAL.start_train_n):\n",
    "        train_window = True\n",
    "    if (i == TRYAL.end_train_n):\n",
    "        train_window = False\n",
    "\n",
    "    if train_window and i % TRYAL.spacing == 0:\n",
    "\n",
    "        if TRAIN_RECURR:\n",
    "            error = X - Target_innate_X[:, i]\n",
    "            for plas in 1:NET.n_plastic\n",
    "\n",
    "        if TRAIN_READOUT:\n",
    "            pass\n",
    "        \n",
    "    Out_history[:, i] = O\n",
    "    X_history[:, [i]] = X\n",
    "    WXOut_len[i] = np.sqrt(np.sum(np.square(WXOut[:])))\n",
    "    WXX_len[i] = np.sqrt(np.sum(np.square(WXX[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 800)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WXOut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 81.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 939 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Out = np.dot(WXOut, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NET.n_plastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw matlab code\n",
    "\n",
    "WXOut_len = np.zeros((1, TRYAL.n_steps))\n",
    "WXX_len = np.zeros((1, TRYAL.n_steps))\n",
    "dW_readout_len = np.zeros((1, TRYAL.n_steps))\n",
    "dW_recurr_len = np.zeros((1, TRYAL.n_steps))\n",
    "train_window = 0\n",
    "\n",
    "# initial conditions\n",
    "Xv = 1*(2*np.random.rand(numUnits,1)-1)\n",
    "X = NET.sigmoid(Xv)\n",
    "Out = np.zeros(numOut,1)\n",
    "\n",
    "\n",
    "# integration loop\n",
    "for i = 1:n_steps\n",
    "\n",
    "    if rem(i,round(n_steps/10)) == 0 && (TRAIN_RECURR == 1 || TRAIN_READOUT == 1)\n",
    "        fprintf('.')\n",
    "    end\n",
    "\n",
    "    in_vec= input_pattern(:,i)\n",
    "\n",
    "    # update units\n",
    "    noise = use_noiseamp*np.random.normal(numUnits,1)*np.sqrt(TRYAL.time_step)\n",
    "    Xv_current = WXX*X + WInputX*in_vec+ noise\n",
    "    Xv = Xv + ((-Xv + Xv_current)./tau)*TRYAL.time_step\n",
    "    X = NET.sigmoid(Xv)\n",
    "    Out = WXOut*X\n",
    "\n",
    "    # start-end training window\n",
    "    if (i == start_train_n)\n",
    "        train_window = 1\n",
    "    end\n",
    "    if (i == end_train_n)\n",
    "        train_window = 0\n",
    "    end\n",
    "\n",
    "    # training\n",
    "    if (train_window == 1 && rem(i,learn_every) == 0)\n",
    "\n",
    "        if TRAIN_RECURR == 1\n",
    "            # train recurrent\n",
    "            error = X - Target_innate_X(:,i)\n",
    "            for plas = 1:numplastic_Units\n",
    "                X_pre_plastic = X(pre_plastic_units(plas).inds)\n",
    "                P_recurr_old = P_recurr(plas).P\n",
    "                P_recurr_old_X = P_recurr_old*X_pre_plastic\n",
    "                den_recurr = 1 + X_pre_plastic'*P_recurr_old_X\n",
    "                P_recurr(plas).P = P_recurr_old - (P_recurr_old_X*P_recurr_old_X')/den_recurr\n",
    "                # update network matrix\n",
    "                dW_recurr = -error(plas)*(P_recurr_old_X/den_recurr)'\n",
    "                WXX(plas,pre_plastic_units(plas).inds) = WXX(plas,pre_plastic_units(plas).inds) + dW_recurr\n",
    "                # store change in weights\n",
    "                dW_recurr_len(i) = dW_recurr_len(i) + np.sqrt(dW_recurr*dW_recurr')\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if TRAIN_READOUT == 1\n",
    "            # update inverse correlation matrix (using property P' = P)\n",
    "            P_readout_old = P_readout\n",
    "            P_readout_old_X = P_readout_old*X\n",
    "            den_readout = 1 + X'*P_readout_old_X\n",
    "            P_readout = P_readout_old - (P_readout_old_X*P_readout_old_X')/den_readout\n",
    "            # update error\n",
    "            error = Out - target_Out(i)\n",
    "            # update output weights\n",
    "            dW_readout = -error*(P_readout_old_X/den_readout)'\n",
    "            WXOut = WXOut + dW_readout\n",
    "            # store change in weights\n",
    "            dW_readout_len(i) = np.sqrt(dW_readout*dW_readout')\n",
    "        end\n",
    "\n",
    "    end\n",
    "    # store output\n",
    "    Out_history(:,i) = Out\n",
    "    X_history(:,i) = X\n",
    "    WXOut_len(i) = np.sqrt(sum(reshape(WXOut.^2,numOut*numUnits,1)))\n",
    "    WXX_len(i) = np.sqrt(sum(reshape(WXX.^2,numUnits^2,1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n",
      "(1, 1600)\n",
      "(1, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x114726550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check: plot input and output patterns\n",
    "\n",
    "print(TRYAL.time_ms.shape)\n",
    "print(IN.series.shape)\n",
    "print(Out.series.shape)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(TRYAL.time_ms, IN.series.T, label='input')\n",
    "ax.plot(TRYAL.time_ms, Out.series.T, label='output')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick verification that all of the following ways of creating\n",
    "# a matrix containing random normal numbers\n",
    "# are equivalent\n",
    "\n",
    "prng = RandomState(1234) # note one needs to re-call this to get same results every time\n",
    "test1 = prng.normal(size=(NET.n_units, NET.n_units)) * NET.scale_recurr\n",
    "\n",
    "prng = RandomState(1234)\n",
    "test2 = prng.normal(scale=NET.scale_recurr, size=(NET.n_units, NET.n_units))\n",
    "\n",
    "prng = RandomState(1234)\n",
    "test3 = norm.rvs(scale=NET.scale_recurr, size=(NET.n_units, NET.n_units), random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allcombs_equal((test1, test2, test3), ck_fun=assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing equality / speed of generating random sparse matrices\n",
    "\n",
    "# method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# uniform distribution for mask\n",
    "prng = RandomState(1234)\n",
    "WXX_mask = prng.rand(NET.n_units, NET.n_units)\n",
    "WXX_mask[WXX_mask <= NET.p_connect] = 1\n",
    "WXX_mask[WXX_mask < 1] = 0\n",
    "\n",
    "# normal distribution for vals\n",
    "prng = RandomState(1234)\n",
    "WXX_vals = prng.normal(scale=NET.scale_recurr, size=(NET.n_units, NET.n_units))\n",
    "\n",
    "# create non-sparse version of WXX and set self-connections (diagonal elements) to 0\n",
    "WXX_nonsparse = WXX_vals * WXX_mask\n",
    "np.fill_diagonal(WXX_nonsparse, 0)\n",
    "# WXX_nonsparse[np.diag_indices_from(WXX_nonsparse)] = 0\n",
    "\n",
    "# convert to be sparse\n",
    "# WXX = coo_matrix(WXX_nonsparse)\n",
    "WXX = csr_matrix(WXX_nonsparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rvs = norm(scale=NET.scale_recurr).rvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelseay/anaconda/lib/python3.5/site-packages/scipy/sparse/compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "# random variable generator object\n",
    "prng = RandomState(1234)\n",
    "WXX_s = random(NET.n_units, NET.n_units, density=NET.p_connect, random_state=prng, data_rvs=rvs,\n",
    "               format='csr',)\n",
    "#                format='csr',)\n",
    "# WXX_s[np.diag_indices_from(WXX_s)] = 0\n",
    "WXX_s.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800) 63797 -0.775266142687 0.726642624784\n"
     ]
    }
   ],
   "source": [
    "cm = WXX_nonsparse\n",
    "print(cm.shape, np.count_nonzero(cm), cm.min(), cm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800) 63797 63797 -0.775266142687 0.726642624784\n",
      "(800, 800) 64723 63923 -0.742525396081 0.73124373277\n"
     ]
    }
   ],
   "source": [
    "ck_mats = (WXX, WXX_s)\n",
    "\n",
    "for cm in ck_mats:\n",
    "    print(cm.shape, cm.nnz, cm.count_nonzero(), cm.min(), cm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "imshow_cb(WXX.toarray(), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "imshow_cb(WXX_s.toarray(), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second method is slower :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_mats = (WXX_nonsparse, WXX, WXX_c, WXX_o, WInputX, WXOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 700 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_ns = WXX_nonsparse*X # SLOW, WRONG SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.41 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 60.6 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1 = WXX*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 62.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_c = WXX_c*X # NO DIFFERENCE WITH ROW / COLUMN SPARSE MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 159 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test1_o = WXX_o*X # COO sparse matrix is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800)\n",
      "(800, 1)\n",
      "(800, 1)\n",
      "(800, 1)\n"
     ]
    }
   ],
   "source": [
    "test1_ns = WXX_nonsparse*X # SLOW, WRONG SHAPE\n",
    "test1 = WXX*X\n",
    "test1_c = WXX_c*X # NO DIFFERENCE WITH ROW / COLUMN SPARSE MATRICES\n",
    "test1_o = WXX_o*X # COO sparse matrix is slower\n",
    "\n",
    "print(test1_ns.shape)\n",
    "print(test1.shape)\n",
    "print(test1_c.shape)\n",
    "print(test1_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck_mats = (test1, test1_c, test1_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats, assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.99 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 69.7 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_ns = WXX_nonsparse.dot(X) # ONLY VERY SLIGHTLY SLOWER THAN\n",
    "# SPARSE, CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 63.1 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2 = WXX.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 62.4 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_c = WXX_c.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 160 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test2_o = WXX_o.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2_ns = WXX_nonsparse.dot(X) # ONLY VERY SLIGHTLY SLOWER THAN\n",
    "# SPARSE, CORRECT BUT NUMERICALLY SLIGHTLY DIFFERENT?\n",
    "test2 = WXX.dot(X)\n",
    "test2_c = WXX_c.dot(X)\n",
    "test2_o = WXX_o.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_mats = (test1, test1_c, test1_o, test2, test2_c, test2_o, test2_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_mats = (test2, test2_c, test2_o,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allcombs_equal(ck_mats, ck_fun=assert_array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing speed of matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 69.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test3_ns = np.matmul(WXX_nonsparse, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object arrays are not currently supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-8f9de1d16825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test3 = np.matmul(WXX, X)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-58>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelseay/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object arrays are not currently supported"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test3 = np.matmul(WXX, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion, for multiplying the sparse matrix by a vector, it's fastest\n",
    "# for a csr_matrix and just use the * operator, it will do the matrix\n",
    "# multiplication in about 60 us"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
